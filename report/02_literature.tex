\section{Literature review}\label{literature review}

This study concerns itself with the ability of algorithms to forge collusion without being explicitly instructed. Situations in which  humans would be unable to achieve such schemes are of special interest. This section provides an overview of academic and institutional assessments of the controversial topic.

First, it is helpful to define collusion. In this text, I will follow \textcite[pp.334-336]{harrington_developing_2018} who recognizes that \emph{supra-competitive} prices, i.e.\ prices above a competitive benchmark, must be underpinned by a \emph{reward-punishment scheme} to be labeled as \emph{collusive}. The scheme is maintained by a mutual understanding that a firm's current behavior affects its competitors' future conduct. Specifically, a participant's adherence to high prices is rewarded with high future prices of competitors ensuring high industry margins. Conversely, deviations are punished with price cuts.\footnote{Of course, competitors can collude not only on prices, but in a variety of ways. The concept easily extends to other dimensions, e.g.\ investment or product quality.} Naturally, it is yet to be seen how likely the scenario of algorithms achieving collusion in real markets is. It is also unclear whether the scenario constitutes illicit behavior and warrants intervention from competition authorities. This question is not a primary concern of this paper. Nevertheless, I will sketch some of the main positions before moving on.

The central issue is that contemporaneous competition policy does not consider collusion itself as illicit behavior. Rather, it is the process, by which it is achieved, that determines legality \parencite[p.339-341]{harrington_developing_2018}. Explicit communication among competitors who consciously agree on price levels is clearly illegal. Smart adaption to market conditions by individual agents is not. These distinct cases are often referred to as \emph{explicit} and \emph{tacit} collusion. Whether to put cooperating algorithms in the former or the latter category is subject to ongoing controversy. A binary answer probably does not do justice to the problem's complexity.  

At the very least, academics consent that algorithms could be utilized to facilitate \emph{existing} collusive agreements \parencite[p.219]{ezrachi_sustainable_2018}. For instance, cartel members could automate detection and punishment of deviations from an agreement through an algorithm. Other conceivable schemes include facilitated market segmentation and price \emph{signalling} \parencite[p.29]{oecd_price_2016}. While these scenarios may alter the operational scope of market investigations to account for the role of deployed algorithms, they are well covered by contemporary competition practices.\footnote{See e.g.\ a joint statement by the German and French federal cartel authorities \parencite{bundeskartellamt_working_nodate} and \textcite{cma_case_2016}, \textcite{oefgen_decision_2019} for two exemplary cases with algorithms \emph{facilitating} collusive agreements.} In fact, the specifics of \emph{facilitating} algorithms might not be highly important because the mere \emph{intention} to collude suffices to invoke competition laws \parencite[p.29]{bundeskartellamt_working_nodate}.

The most interesting scenario concerns independently developed or acquired algorithms that align pricing behavior. The US Department of Justice states that competitors are unlikely to be held liable if they independently adopt similar pricing software \parencite[p.6]{doj_algorithms_2017}. A note from the European Union indicates that companies can not expect to completely avoid liability by referring to their pricing algorithms. Moreover, they do not rule out the option that algorithms \emph{decoding} each other may be within the scope of explicit communication \parencite[p.8-9]{eu_algorithms_2017}. 

\textcite[pp.105-106]{gal_algorithms_2019} argues that in the special case of \emph{rule based} algorithms, a programmer's intent to create coordination could in principal be derived from her developed code. For instance, the conscious decision to include punishment mechanisms if a competitor's price falls below a certain threshold seems incriminating. However, many algorithms do not follow a rigid set of rules. Rather, its programmer defines higher-level objectives such as \emph{profit maximization} and the algorithm itself figures out how to act in a specific situation based on data and experience.\footnote{Every form of reinforcement learning falls into this second category.} Obviously, it is hard to infer intent from these types of algorithms. On a similar note, \textcite[p.350-351]{harrington_developing_2018} emphasizes that determining intentions from program code is conceptually appealing, but costly to implement.

\textcite{mehra_antitrust_2015} takes a more controversial view. He points out that the traditional distinction between explicit and tacit collusion emerged with human agents in mind and competition laws did not foresee pricing algorithms that are more likely to achieve cartel solutions in oligopolistic settings due to superior speed, accuracy and even rationality when analyzing and adjusting prices. Consequently, he argues that the increasing prevalence of automated pricing software warrants a reassessment of current competition law and enforcement. Moving forward, I will discuss the likelihood of collusion among algorithms arising in real markets. Due to a lack of empirical evidence, I will focus on theoretical considerations and simulation studies.

As pointed out earlier, the scarcity of field studies on pricing algorithms in real markets prohibits generalized conclusions. However, theoretical considerations might shed light on when algorithmic coordination is a valid concern. Any form of collusion requires timely detection of deviations and a credible threat of punishment \parencite[pp.48-56]{stigler_theory_1964}.\footnote{Naturally, industry characteristics play an important role (e.g.\ number of firms, market entry barriers or product homogeneity). See \textcite[p.142-149]{motta_competition_2004} for an extensive list of structural factors and their impact on the likelihood of collusion arising.}  Surely, algorithms are able to fulfill these conditions but so do humans. \textcite{schwalbe_algorithms_2018} argues that the advent of algorithms does not raise \emph{novel} competition problems. Indeed, humans might be replaced by pricing software but this does not inevitably make collusion more likely. The argument is strengthened by a list of experimental settings where algorithms fail to cooperate. Schwalbe stresses that the ability to communicate is vital to achieve collusive outcomes in markets with more than two participants and raises the question whether algorithms are better at communicating than humans.

\textcite[p.10-13]{ittoo_algorithmic_2017} emphasize the challenges associated with applying \emph{reinforcement learning} algorithms to real markets. First, there are practical implementation issues and mapping real market conditions to a reinforcement learning data problem is not always natural. Second, convergence guarantees break down as soon as the market is subject to changing conditions.\footnote{Technically, guarantees of convergence in reinforcement learning tasks are only valid if the environment is stationary, an assumption that is violated if demand conditions change or competitors price dynamically (see \autoref{convergence_considerations}). However, absence of convergence guarantees does not render convergence impossible.} Third, tabular learning methods do not scale well with the complexity of learning tasks. Consequently, mastering collusion might take a long time.\footnote{I will revisit this point in \autoref{tabular}.} They conclude that the deployment of pricing algorithms possibly, but not inevitably, leads to collusive outcomes.

\textcite[pp.6-17]{ezrachi_algorithmic_2017} argue that algorithms have the potential to establish tacit collusion in markets where conscious parallelism among humans is unrealistic. For instance, they develop a \emph{hub and spoke} scenario in which a third party software vendor provides the same or a similar pricing algorithm to competing sellers. The single algorithm could then align the pricing behavior of competitors resulting in conditions conducive to collusion. The authors suggest counter measures such as imposing restrictions on the allowed frequency of price changes or artificially reducing price transparency.


While there are numerous studies on the behavior of learning algorithms in cooperative and competitive multi-agent games\footnote{See e.g.\ \textcite{leibo_multi-agent_2017} and \textcite{crandall_cooperating_2018} for recent large-scale experimental studies.}, their application in oligopolistic environments has been rare and the trialed algorithms have been relatively simple. A seminal study by \textcite{waltman_q-learning_2008} examines two \emph{Q-Learning} agents in a \emph{Cournot} environment. Their simulations result in supra-competitive outcomes. However, even \emph{memoryless} agents without knowledge of past outcomes manage to attain quantities below the one-shot Nash equilibrium. This casts doubt on the viability of the learned strategies vis-Ã -vis rational agents. Truly memoryless agents can not pursue \emph{punishment strategies} because they are unable to even detect them. Thus, constantly playing the one-shot solution \emph{should} be the only rational strategy. It appears, the agents do not \emph{learn how to collude}, but rather \emph{fail to learn how to compete}.

Two further studies that model agents in games of infinitely repeated quantity competition should be mentioned. Inspired by the management literature, \textcite{kimbrough_learning_2009} trial a \emph{probe and adjust} algorithm.\footnote{To my knowledge, \emph{probe and adjust} is the only algorithm that explored continuous price setting in repeated games of competition to date.} Their agents repeatedly draw prices from a continuous price range. After some time, they assess whether low or high prices yielded better rewards and adjust the range of prices accordingly. They find that agents end up playing one-shot Nash prices unless industry profits enter the reward function in some way. \textcite{siallagan_aspiration-based_2013} propose \emph{aspiration based} learning where agents are allowed to communicate expectations to each other. They find that supra-competitive prices are attainable if the number of available options does not exceed 3.

Recent studies have focused on price instead of quantity competition. \textcite{klein_autonomous_2019} shows that \emph{Q-Learning} algorithms in a sequential price setting environment maintain a supra-competitive price level. He reports two types of equilibria: constant market prices and \emph{Edgeworth price cycles} where competitors sequentially undercut each other until profits become low and one firm resets the cycle by increasing its price significantly.\footnote{\textcite{noel_edgeworth_2008} considers a similar environment. However, he uses \emph{dynamic programming} for learning. His deployed agents \emph{know} their environment in detail, an assumption unlikely to hold in real markets. With \emph{Q-Learning}, agents estimate the action values based on past experiences.} Importantly, the high price levels are underpinned by a \emph{reward-punishment scheme}, i.e.\ a price cut of one agent evokes punishment prices by the opponent. Interestingly, the agents return to pre-deviaton levels within a couple of periods.

This study is closest to \textcite{calvano_artificial_2020} and \textcite{hettich_algorithmic_2021}. The former authors show that Q-Learning agents learn to sustain collusion through a \emph{reward-punishment} scheme in a simultaneous pricing environment. These findings are remarkably robust to variations and extensions. Furthermore, they find that agents learn to price competitively if they are memoryless (i.e.\ can not remember past prices) or short-sighted (i.e.\ do not value future profits). This coincides with predictions from economic theory. An important extension comes from \textcite{hettich_algorithmic_2021}. As in the present study, he utilizes function approximation, specifically a \emph{deep Q-Network algorithm} originally due to \textcite{mnih_human-level_2015}. He shows that the method converges much faster than \emph{Q-Learning}. The importance of that finding is augmented by the fact that the algorithm is much easier to scale to real applications.\footnote{\textcite{johnson_platform_2020} provide another extension. Introducing a \emph{multi-agent reinforcement learning} approach, they show that collusion arises even when the number of agents, often regarded a main inhibitor of cooperative behavior, is significantly increased. Moreover, they show that market design can significantly disturb collusion.}

To summarize, recent simulation studies show that reinforcement learning algorithms are capable of colluding in prefabricated environments. This paper tries to extend those findings by trialing \emph{linear} function approximation and eligibility traces.





